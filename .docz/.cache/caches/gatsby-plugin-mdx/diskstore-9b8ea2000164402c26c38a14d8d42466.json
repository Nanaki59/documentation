{"expireTime":9007200861652441000,"key":"gatsby-plugin-mdx-entire-payload-98c84b6de98681eaffed2ec3821e8199-","val":{"mdast":{"type":"root","children":[{"type":"import","value":"import DefaultLayout from \"/Users/i353408/Vagrant/www/repos/documentation/node_modules/gatsby-theme-docz/src/base/Layout.js\"","position":{"start":{"line":3,"column":1,"offset":2},"end":{"line":3,"column":125,"offset":126},"indent":[]}},{"type":"export","default":true,"value":"export default DefaultLayout","position":{"start":{"line":5,"column":1,"offset":128},"end":{"line":5,"column":29,"offset":156},"indent":[]}},{"type":"import","value":"import ReplaceVersion from \"../components/ReplaceVersion\";","position":{"start":{"line":8,"column":1,"offset":159},"end":{"line":8,"column":59,"offset":217},"indent":[]}},{"type":"heading","depth":1,"children":[{"type":"text","value":"Introduction","position":{"start":{"line":10,"column":3,"offset":221},"end":{"line":10,"column":15,"offset":233},"indent":[]}}],"position":{"start":{"line":10,"column":1,"offset":219},"end":{"line":10,"column":15,"offset":233},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Welcome to the Kerberos Enterprise Edge installation. This is the way to go if you want to install Kerberos Enterprise on your Baremetal infrastructure or inside your Private Cloud.","position":{"start":{"line":12,"column":1,"offset":235},"end":{"line":12,"column":182,"offset":416},"indent":[]}}],"position":{"start":{"line":12,"column":1,"offset":235},"end":{"line":12,"column":182,"offset":416},"indent":[]}},{"type":"paragraph","children":[{"type":"image","title":null,"url":"../../public/images/kerberos-agent-architecture-kubernetes.png","alt":"architecture kubernetes","position":{"start":{"line":14,"column":1,"offset":418},"end":{"line":14,"column":91,"offset":508},"indent":[]}}],"position":{"start":{"line":14,"column":1,"offset":418},"end":{"line":14,"column":91,"offset":508},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Before we can actual start installing the different deployments in our cluster, we need to make sure we have one available.","position":{"start":{"line":16,"column":1,"offset":510},"end":{"line":16,"column":124,"offset":633},"indent":[]}}],"position":{"start":{"line":16,"column":1,"offset":510},"end":{"line":16,"column":124,"offset":633},"indent":[]}},{"type":"heading","depth":1,"children":[{"type":"text","value":"Prerequisites","position":{"start":{"line":18,"column":3,"offset":637},"end":{"line":18,"column":16,"offset":650},"indent":[]}}],"position":{"start":{"line":18,"column":1,"offset":635},"end":{"line":18,"column":16,"offset":650},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Docker","position":{"start":{"line":20,"column":4,"offset":655},"end":{"line":20,"column":10,"offset":661},"indent":[]}}],"position":{"start":{"line":20,"column":1,"offset":652},"end":{"line":20,"column":10,"offset":661},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"If you have a fresh Linux installation, make sure you have Docker installed. If not the case, this is how you can install it on a Ubuntu OSS.","position":{"start":{"line":22,"column":1,"offset":663},"end":{"line":22,"column":142,"offset":804},"indent":[]}}],"position":{"start":{"line":22,"column":1,"offset":663},"end":{"line":22,"column":142,"offset":804},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"apt install docker.io -y","position":{"start":{"line":24,"column":1,"offset":806},"end":{"line":24,"column":29,"offset":834},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Kubernetes","position":{"start":{"line":26,"column":4,"offset":839},"end":{"line":26,"column":14,"offset":849},"indent":[]}}],"position":{"start":{"line":26,"column":1,"offset":836},"end":{"line":26,"column":14,"offset":849},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"After Docker being installed go ahead and install the different Kubernetes servicess and tools.","position":{"start":{"line":28,"column":1,"offset":851},"end":{"line":28,"column":96,"offset":946},"indent":[]}}],"position":{"start":{"line":28,"column":1,"offset":851},"end":{"line":28,"column":96,"offset":946},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"apt update -y\napt install apt-transport-https curl -y\ncurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add\napt-add-repository \"deb http://apt.kubernetes.io/ kubernetes-xenial main\"\napt update -y && apt install kubeadm kubelet kubectl kubernetes-cni -y","position":{"start":{"line":30,"column":1,"offset":948},"end":{"line":34,"column":75,"offset":1242},"indent":[1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Make sure you disable swap, this is required by Kubernetes.","position":{"start":{"line":36,"column":1,"offset":1244},"end":{"line":36,"column":60,"offset":1303},"indent":[]}}],"position":{"start":{"line":36,"column":1,"offset":1244},"end":{"line":36,"column":60,"offset":1303},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"swapoff -a","position":{"start":{"line":38,"column":1,"offset":1305},"end":{"line":38,"column":15,"offset":1319},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"And if you want to make it permanent after every boot.","position":{"start":{"line":40,"column":1,"offset":1321},"end":{"line":40,"column":55,"offset":1375},"indent":[]}}],"position":{"start":{"line":40,"column":1,"offset":1321},"end":{"line":40,"column":55,"offset":1375},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"sudo sed -i.bak '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab","position":{"start":{"line":42,"column":1,"offset":1377},"end":{"line":42,"column":59,"offset":1435},"indent":[]}},{"type":"heading","depth":1,"children":[{"type":"text","value":"Installation","position":{"start":{"line":44,"column":3,"offset":1439},"end":{"line":44,"column":15,"offset":1451},"indent":[]}}],"position":{"start":{"line":44,"column":1,"offset":1437},"end":{"line":44,"column":15,"offset":1451},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Before initiating a new Kubernetes cluster, make sure you have properly cleaned up previous installation (if this was the case ofc).","position":{"start":{"line":46,"column":1,"offset":1453},"end":{"line":46,"column":133,"offset":1585},"indent":[]}}],"position":{"start":{"line":46,"column":1,"offset":1453},"end":{"line":46,"column":133,"offset":1585},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"kubeadm reset\nrm -rf $HOME/.kube","position":{"start":{"line":48,"column":1,"offset":1587},"end":{"line":49,"column":23,"offset":1627},"indent":[1]}},{"type":"paragraph","children":[{"type":"text","value":"Initiate a new Kubernetes cluster using following command. This will use the current CIDR. If you want to use another CIDR, specify following arguments: ","position":{"start":{"line":51,"column":1,"offset":1629},"end":{"line":51,"column":154,"offset":1782},"indent":[]}},{"type":"inlineCode","value":"--pod-network-cidr=10.244.0.0/16","position":{"start":{"line":51,"column":154,"offset":1782},"end":{"line":51,"column":188,"offset":1816},"indent":[]}},{"type":"text","value":".","position":{"start":{"line":51,"column":188,"offset":1816},"end":{"line":51,"column":189,"offset":1817},"indent":[]}}],"position":{"start":{"line":51,"column":1,"offset":1629},"end":{"line":51,"column":189,"offset":1817},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"kubeadm init","position":{"start":{"line":53,"column":1,"offset":1819},"end":{"line":53,"column":17,"offset":1835},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Once successful you should see the following. Note the ","position":{"start":{"line":55,"column":1,"offset":1837},"end":{"line":55,"column":56,"offset":1892},"indent":[]}},{"type":"inlineCode","value":"discovery token","position":{"start":{"line":55,"column":56,"offset":1892},"end":{"line":55,"column":73,"offset":1909},"indent":[]}},{"type":"text","value":" which you need to use to connect additional nodes to your cluster.","position":{"start":{"line":55,"column":73,"offset":1909},"end":{"line":55,"column":140,"offset":1976},"indent":[]}}],"position":{"start":{"line":55,"column":1,"offset":1837},"end":{"line":55,"column":140,"offset":1976},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"Your Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.1.103:6443 --token ej7ckt.uof7o2iplqf0r2up \\\n    --discovery-token-ca-cert-hash sha256:9cbcc00d34be2dbd605174802d9e52fbcdd617324c237bf58767b369fa586209","position":{"start":{"line":57,"column":1,"offset":1978},"end":{"line":72,"column":111,"offset":2753},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Now we have a Kubernetes cluster, we need to make sure we add make it available in our ","position":{"start":{"line":74,"column":1,"offset":2755},"end":{"line":74,"column":88,"offset":2842},"indent":[]}},{"type":"inlineCode","value":"kubeconfig","position":{"start":{"line":74,"column":88,"offset":2842},"end":{"line":74,"column":100,"offset":2854},"indent":[]}},{"type":"text","value":". This will allow us to query our Kubernetes cluster with the ","position":{"start":{"line":74,"column":100,"offset":2854},"end":{"line":74,"column":162,"offset":2916},"indent":[]}},{"type":"inlineCode","value":"kubectl","position":{"start":{"line":74,"column":162,"offset":2916},"end":{"line":74,"column":171,"offset":2925},"indent":[]}},{"type":"text","value":" command.","position":{"start":{"line":74,"column":171,"offset":2925},"end":{"line":74,"column":180,"offset":2934},"indent":[]}}],"position":{"start":{"line":74,"column":1,"offset":2755},"end":{"line":74,"column":180,"offset":2934},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"mkdir -p $HOME/.kube\ncp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nchown $(id -u):$(id -g) $HOME/.kube/config","position":{"start":{"line":76,"column":1,"offset":2936},"end":{"line":78,"column":47,"offset":3063},"indent":[1,1]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Untaint all nodes","position":{"start":{"line":80,"column":4,"offset":3068},"end":{"line":80,"column":21,"offset":3085},"indent":[]}}],"position":{"start":{"line":80,"column":1,"offset":3065},"end":{"line":80,"column":21,"offset":3085},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"By default, and in this example, we only have one node our master node. In a production scenario we would have additional worker nodes. By default the master nodes are marked as ","position":{"start":{"line":82,"column":1,"offset":3087},"end":{"line":82,"column":179,"offset":3265},"indent":[]}},{"type":"inlineCode","value":"tainted","position":{"start":{"line":82,"column":179,"offset":3265},"end":{"line":82,"column":188,"offset":3274},"indent":[]}},{"type":"text","value":", this means they cannot run workloads. To allow master nodes to run workloads, we need to untaint them. If we wouldn't do this our pods would never be scheduled, as we do not have worker nodes at this moment.","position":{"start":{"line":82,"column":188,"offset":3274},"end":{"line":82,"column":397,"offset":3483},"indent":[]}}],"position":{"start":{"line":82,"column":1,"offset":3087},"end":{"line":82,"column":397,"offset":3483},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"kubectl taint nodes --all node-role.kubernetes.io/master-","position":{"start":{"line":84,"column":1,"offset":3485},"end":{"line":84,"column":62,"offset":3546},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Calico","position":{"start":{"line":86,"column":4,"offset":3551},"end":{"line":86,"column":10,"offset":3557},"indent":[]}}],"position":{"start":{"line":86,"column":1,"offset":3548},"end":{"line":86,"column":10,"offset":3557},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Calico is an open source networking and network security solution for containers, virtual machines, and native host-based workloads. (","position":{"start":{"line":88,"column":1,"offset":3559},"end":{"line":88,"column":135,"offset":3693},"indent":[]}},{"type":"link","title":null,"url":"https://www.projectcalico.org/","children":[{"type":"text","value":"https://www.projectcalico.org/","position":{"start":{"line":88,"column":135,"offset":3693},"end":{"line":88,"column":165,"offset":3723},"indent":[]}}],"position":{"start":{"line":88,"column":135,"offset":3693},"end":{"line":88,"column":165,"offset":3723},"indent":[]}},{"type":"text","value":"). We will use it as our network layer in our Kubernetes cluster. You could use otthers like Flannel aswell, but we prefer Calico.","position":{"start":{"line":88,"column":165,"offset":3723},"end":{"line":88,"column":295,"offset":3853},"indent":[]}}],"position":{"start":{"line":88,"column":1,"offset":3559},"end":{"line":88,"column":295,"offset":3853},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"curl https://docs.projectcalico.org/manifests/calico.yaml -O\nkubectl apply -f calico.yaml","position":{"start":{"line":90,"column":1,"offset":3855},"end":{"line":91,"column":33,"offset":3952},"indent":[1]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Kerberos Enterprise","position":{"start":{"line":93,"column":4,"offset":3957},"end":{"line":93,"column":23,"offset":3976},"indent":[]}}],"position":{"start":{"line":93,"column":1,"offset":3954},"end":{"line":93,"column":23,"offset":3976},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Before setting up Kerberos Enterprise, some configuration needs to happen. First thing that we need to do is setting up the RBAC permissions (Role Based Access Control). We need to enable this to be able to query specific endpoints from the Kubernetes API. By default these endpoints are locked, so we need to unlock them.","position":{"start":{"line":95,"column":1,"offset":3978},"end":{"line":95,"column":323,"offset":4300},"indent":[]}}],"position":{"start":{"line":95,"column":1,"offset":3978},"end":{"line":95,"column":323,"offset":4300},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"git clone https://github.com/kerberos-io/enterprise\nkubectl create -f ./enterprise/yaml/factory/clusterrole.yaml","position":{"start":{"line":97,"column":1,"offset":4302},"end":{"line":98,"column":65,"offset":4422},"indent":[1]}},{"type":"paragraph","children":[{"type":"text","value":"This will make several actions, permissions, inside your cluster available. We need this to be able to create deployments from the Kerberos Enterprise web app.","position":{"start":{"line":100,"column":1,"offset":4424},"end":{"line":100,"column":160,"offset":4583},"indent":[]}}],"position":{"start":{"line":100,"column":1,"offset":4424},"end":{"line":100,"column":160,"offset":4583},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"MetalLB","position":{"start":{"line":102,"column":4,"offset":4588},"end":{"line":102,"column":11,"offset":4595},"indent":[]}}],"position":{"start":{"line":102,"column":1,"offset":4585},"end":{"line":102,"column":11,"offset":4595},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"In the Edge world, we do not have fancy Load balancers and Public IP from which we can benefit. To overcome this solutions such as MetalLB - Baremetal Load Balancer - have been developed (","position":{"start":{"line":104,"column":1,"offset":4597},"end":{"line":104,"column":189,"offset":4785},"indent":[]}},{"type":"link","title":null,"url":"https://metallb.universe.tf/installation/","children":[{"type":"text","value":"https://metallb.universe.tf/installation/","position":{"start":{"line":104,"column":189,"offset":4785},"end":{"line":104,"column":230,"offset":4826},"indent":[]}}],"position":{"start":{"line":104,"column":189,"offset":4785},"end":{"line":104,"column":230,"offset":4826},"indent":[]}},{"type":"text","value":"). MetalLB will dedicate an internal IP address, or IP range, which will be assigned to one or more Load Balancers.","position":{"start":{"line":104,"column":230,"offset":4826},"end":{"line":104,"column":345,"offset":4941},"indent":[]}}],"position":{"start":{"line":104,"column":1,"offset":4597},"end":{"line":104,"column":345,"offset":4941},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.5/manifests/namespace.yaml\nkubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.5/manifests/metallb.yaml\nkubectl create secret generic -n metallb-system memberlist --from-literal=secretkey=\"$(openssl rand -base64 128)\"","position":{"start":{"line":106,"column":1,"offset":4943},"end":{"line":108,"column":118,"offset":5264},"indent":[1,1]}},{"type":"paragraph","children":[{"type":"text","value":"After installing the different MetalLB components, we need to create a ","position":{"start":{"line":110,"column":1,"offset":5266},"end":{"line":110,"column":72,"offset":5337},"indent":[]}},{"type":"inlineCode","value":"configmap.yaml","position":{"start":{"line":110,"column":72,"offset":5337},"end":{"line":110,"column":88,"offset":5353},"indent":[]}},{"type":"text","value":" file. This file contains information of how MetalLB can get and use internal IP's as LoadBalancers.","position":{"start":{"line":110,"column":88,"offset":5353},"end":{"line":110,"column":188,"offset":5453},"indent":[]}}],"position":{"start":{"line":110,"column":1,"offset":5266},"end":{"line":110,"column":188,"offset":5453},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"  apiVersion: v1\n  kind: ConfigMap\n  metadata:\n    namespace: metallb-system\n    name: config\n  data:\n    config: |\n      address-pools:\n      - name: default\n        protocol: layer2\n        addresses:\n-->     - 192.168.1.200-192.168.1.210","position":{"start":{"line":112,"column":1,"offset":5455},"end":{"line":123,"column":42,"offset":5743},"indent":[1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"You can change the IP range above to match your needs. MetalLB will use this range as a referance to assign IP addresses to your LoadBalancers. Once ready you can apply the configration map.","position":{"start":{"line":125,"column":1,"offset":5745},"end":{"line":125,"column":191,"offset":5935},"indent":[]}}],"position":{"start":{"line":125,"column":1,"offset":5745},"end":{"line":125,"column":191,"offset":5935},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"kubectl apply -f ./enterprise/yaml/metallb/configmap.yaml","position":{"start":{"line":127,"column":1,"offset":5937},"end":{"line":127,"column":62,"offset":5998},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Helm","position":{"start":{"line":129,"column":4,"offset":6003},"end":{"line":129,"column":8,"offset":6007},"indent":[]}}],"position":{"start":{"line":129,"column":1,"offset":6000},"end":{"line":129,"column":8,"offset":6007},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Before we can start with the real work, I know we had to do a lot of preparation, we have to install another helpful tool ","position":{"start":{"line":131,"column":1,"offset":6009},"end":{"line":131,"column":123,"offset":6131},"indent":[]}},{"type":"inlineCode","value":"Helm","position":{"start":{"line":131,"column":123,"offset":6131},"end":{"line":131,"column":129,"offset":6137},"indent":[]}},{"type":"text","value":". Helm is a package manager for Kubernetes, and really makes you life easier.","position":{"start":{"line":131,"column":129,"offset":6137},"end":{"line":131,"column":206,"offset":6214},"indent":[]}}],"position":{"start":{"line":131,"column":1,"offset":6009},"end":{"line":131,"column":206,"offset":6214},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3\nchmod 700 get_helm.sh\n./get_helm.sh","position":{"start":{"line":133,"column":1,"offset":6216},"end":{"line":135,"column":18,"offset":6359},"indent":[1,1]}},{"type":"paragraph","children":[{"type":"text","value":"This will make sure helm 3 is installed.","position":{"start":{"line":137,"column":1,"offset":6361},"end":{"line":137,"column":41,"offset":6401},"indent":[]}}],"position":{"start":{"line":137,"column":1,"offset":6361},"end":{"line":137,"column":41,"offset":6401},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Traefik","position":{"start":{"line":139,"column":4,"offset":6406},"end":{"line":139,"column":11,"offset":6413},"indent":[]}}],"position":{"start":{"line":139,"column":1,"offset":6403},"end":{"line":139,"column":11,"offset":6413},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"To access the Kerberos Enterprise web application, we will create a service in the next paragraphs. This service will expose the web application as an Ingress. Thanks to our previous installation with MetalLB and Traefik (what we will do now), we will have a neat solution for managing our hostnames and Load Balancing IPs.","position":{"start":{"line":141,"column":1,"offset":6415},"end":{"line":141,"column":324,"offset":6738},"indent":[]}}],"position":{"start":{"line":141,"column":1,"offset":6415},"end":{"line":141,"column":324,"offset":6738},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"The idea is that Traefik, will have a dedicated IP address assigned from MetalLB, and will resolve the Ingress of our Kerberos Enterprise web app. Let's go ahead with installing Traefik.","position":{"start":{"line":143,"column":1,"offset":6740},"end":{"line":143,"column":187,"offset":6926},"indent":[]}}],"position":{"start":{"line":143,"column":1,"offset":6740},"end":{"line":143,"column":187,"offset":6926},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"helm repo add stable https://charts.helm.sh/stable\nhelm install traefik -f ./enterprise/yaml/traefik/values.yaml stable/traefik","position":{"start":{"line":145,"column":1,"offset":6928},"end":{"line":146,"column":81,"offset":7063},"indent":[1]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"MongoDB","position":{"start":{"line":148,"column":4,"offset":7068},"end":{"line":148,"column":11,"offset":7075},"indent":[]}}],"position":{"start":{"line":148,"column":1,"offset":7065},"end":{"line":148,"column":11,"offset":7075},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"When using Kerberos Enterprise, it will generate configurations for every surveillance camera deployed. These configuration files are stored centrally in a MongoDB database. Therefore we use ","position":{"start":{"line":150,"column":1,"offset":7077},"end":{"line":150,"column":192,"offset":7268},"indent":[]}},{"type":"inlineCode","value":"helm","position":{"start":{"line":150,"column":192,"offset":7268},"end":{"line":150,"column":198,"offset":7274},"indent":[]}},{"type":"text","value":" to install a MongoDB instance inside your cluster.","position":{"start":{"line":150,"column":198,"offset":7274},"end":{"line":150,"column":249,"offset":7325},"indent":[]}}],"position":{"start":{"line":150,"column":1,"offset":7077},"end":{"line":150,"column":249,"offset":7325},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Before we can move into the installation of MongoDB, in contrary with the cloud installation, we will need to create a Persistent Volume (PV). For simplicity we will use ","position":{"start":{"line":152,"column":1,"offset":7327},"end":{"line":152,"column":171,"offset":7497},"indent":[]}},{"type":"inlineCode","value":"local-storage","position":{"start":{"line":152,"column":171,"offset":7497},"end":{"line":152,"column":186,"offset":7512},"indent":[]}},{"type":"text","value":", and make sure the volume is assigned to a specific node (hostname).","position":{"start":{"line":152,"column":186,"offset":7512},"end":{"line":152,"column":255,"offset":7581},"indent":[]}}],"position":{"start":{"line":152,"column":1,"offset":7327},"end":{"line":152,"column":255,"offset":7581},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Create a folder on the node (VM), where you want to persist the data of MongoDB.","position":{"start":{"line":154,"column":1,"offset":7583},"end":{"line":154,"column":81,"offset":7663},"indent":[]}}],"position":{"start":{"line":154,"column":1,"offset":7583},"end":{"line":154,"column":81,"offset":7663},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"mkdir /home/mongodb/","position":{"start":{"line":156,"column":1,"offset":7665},"end":{"line":156,"column":25,"offset":7689},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Once done open the ","position":{"start":{"line":158,"column":1,"offset":7691},"end":{"line":158,"column":20,"offset":7710},"indent":[]}},{"type":"inlineCode","value":"./enterprise/yaml/mongodb/volume.yaml","position":{"start":{"line":158,"column":20,"offset":7710},"end":{"line":158,"column":59,"offset":7749},"indent":[]}},{"type":"text","value":" file and make sure to change capacity, local path (if changed) and the hostname attribute (VM/machine, on which the directory is made available).","position":{"start":{"line":158,"column":59,"offset":7749},"end":{"line":158,"column":205,"offset":7895},"indent":[]}}],"position":{"start":{"line":158,"column":1,"offset":7691},"end":{"line":158,"column":205,"offset":7895},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"    spec:\n      capacity:\n-->    storage: 10Gi\n      accessModes:\n      - ReadWriteOnce\n      persistentVolumeReclaimPolicy: Recycle\n      storageClassName: local-storage\n      local:\n-->    path: /home/mongodb/\n      nodeAffinity:\n        required:\n          nodeSelectorTerms:\n          - matchExpressions:\n            - key: kubernetes.io/hostname\n              operator: In\n              values:\n-->           - hostname","position":{"start":{"line":160,"column":1,"offset":7897},"end":{"line":176,"column":29,"offset":8389},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"After modified properly you can go ahead with creating the PV.","position":{"start":{"line":178,"column":1,"offset":8391},"end":{"line":178,"column":63,"offset":8453},"indent":[]}}],"position":{"start":{"line":178,"column":1,"offset":8391},"end":{"line":178,"column":63,"offset":8453},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"kubectl create -f ./enterprise/yaml/mongodb/volume.yaml","position":{"start":{"line":180,"column":1,"offset":8455},"end":{"line":180,"column":60,"offset":8514},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Have a look into the ","position":{"start":{"line":182,"column":1,"offset":8516},"end":{"line":182,"column":22,"offset":8537},"indent":[]}},{"type":"inlineCode","value":"yaml/mongodb/values.yaml","position":{"start":{"line":182,"column":22,"offset":8537},"end":{"line":182,"column":48,"offset":8563},"indent":[]}},{"type":"text","value":" file, you will find plenty of configurations for your MongoDB instance. You will also find the attribute where you can change the root password of mongodb. If using Helm version 2, write ","position":{"start":{"line":182,"column":48,"offset":8563},"end":{"line":182,"column":236,"offset":8751},"indent":[]}},{"type":"inlineCode","value":"--name mongodb","position":{"start":{"line":182,"column":236,"offset":8751},"end":{"line":182,"column":252,"offset":8767},"indent":[]}},{"type":"text","value":".","position":{"start":{"line":182,"column":252,"offset":8767},"end":{"line":182,"column":253,"offset":8768},"indent":[]}}],"position":{"start":{"line":182,"column":1,"offset":8516},"end":{"line":182,"column":253,"offset":8768},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"helm repo add bitnami https://charts.bitnami.com/bitnami\nhelm install mongodb bitnami/mongodb --values ./yaml/mongodb/values-edge.yaml","position":{"start":{"line":184,"column":1,"offset":8770},"end":{"line":185,"column":82,"offset":8912},"indent":[1]}},{"type":"paragraph","children":[{"type":"text","value":"Once installed succesfully the MongoDB instance, we should copy the password of the MongoDB instance. Once revealed copy the password, as we will need in the next steps.","position":{"start":{"line":187,"column":1,"offset":8914},"end":{"line":187,"column":170,"offset":9083},"indent":[]}}],"position":{"start":{"line":187,"column":1,"offset":8914},"end":{"line":187,"column":170,"offset":9083},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"export MONGODB_ROOT_PASSWORD=$(kubectl get secret --namespace default mongodb -o jsonpath=\"{.data.mongodb-root-password}\" | base64 --decode)\necho $MONGODB_ROOT_PASSWORD","position":{"start":{"line":189,"column":1,"offset":9085},"end":{"line":190,"column":32,"offset":9261},"indent":[1]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Kerberos Enterprise Web App - The Factory","position":{"start":{"line":192,"column":4,"offset":9266},"end":{"line":192,"column":45,"offset":9307},"indent":[]}}],"position":{"start":{"line":192,"column":1,"offset":9263},"end":{"line":192,"column":45,"offset":9307},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"The last step is to install the Kerberos Enterprise application. Kerberos Enterprise is managed through an application which we call the ","position":{"start":{"line":194,"column":1,"offset":9309},"end":{"line":194,"column":138,"offset":9446},"indent":[]}},{"type":"inlineCode","value":"Factory","position":{"start":{"line":194,"column":138,"offset":9446},"end":{"line":194,"column":147,"offset":9455},"indent":[]}},{"type":"text","value":". It is responsible for initiating the deployments inside your cluster. These deployments is what we also call (similar to the Open Source version) the machinery.","position":{"start":{"line":194,"column":147,"offset":9455},"end":{"line":194,"column":309,"offset":9617},"indent":[]}}],"position":{"start":{"line":194,"column":1,"offset":9309},"end":{"line":194,"column":309,"offset":9617},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"The Factory is shipped as a web app (React) which provides you with a tool to update your deployments (agents) easily, monitor them, etc. The Factory is the central portal for managing Kerberos Enterprise inside your cluster. However at any point you can fine-tune or take-over using the ","position":{"start":{"line":196,"column":1,"offset":9619},"end":{"line":196,"column":289,"offset":9907},"indent":[]}},{"type":"inlineCode","value":"kubectl","position":{"start":{"line":196,"column":289,"offset":9907},"end":{"line":196,"column":298,"offset":9916},"indent":[]}},{"type":"text","value":" command.","position":{"start":{"line":196,"column":298,"offset":9916},"end":{"line":196,"column":307,"offset":9925},"indent":[]}}],"position":{"start":{"line":196,"column":1,"offset":9619},"end":{"line":196,"column":307,"offset":9925},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Before installing the Factory web app, open the ","position":{"start":{"line":198,"column":1,"offset":9927},"end":{"line":198,"column":49,"offset":9975},"indent":[]}},{"type":"inlineCode","value":"./enterprise/yaml/factory/deployment.yaml","position":{"start":{"line":198,"column":49,"offset":9975},"end":{"line":198,"column":92,"offset":10018},"indent":[]}},{"type":"text","value":" configuration file. At the bottom file you will find two endpoints, similar to the traefik config file. Update the domain names to your own domain, and add these to your DNS server (pointing to the same IP as the traefik EXTERNAL-IP).","position":{"start":{"line":198,"column":92,"offset":10018},"end":{"line":198,"column":327,"offset":10253},"indent":[]}}],"position":{"start":{"line":198,"column":1,"offset":9927},"end":{"line":198,"column":327,"offset":10253},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"    spec:\n      rules:\n-->   - host: factory.domain.com\n        http:\n          paths:\n          - path: /\n            backend:\n              serviceName: factory\n              servicePort: 80\n-->   - host: api.factory.domain.com\n        http:\n          paths:\n          - path: /\n            backend:\n              serviceName: factory\n              servicePort: 8081","position":{"start":{"line":200,"column":1,"offset":10255},"end":{"line":215,"column":36,"offset":10687},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Modify the MongoDB credentials, and make sure they match the credentials of your MongoDB instance.","position":{"start":{"line":217,"column":1,"offset":10689},"end":{"line":217,"column":99,"offset":10787},"indent":[]}}],"position":{"start":{"line":217,"column":1,"offset":10689},"end":{"line":217,"column":99,"offset":10787},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"    - name: MONGODB_USERNAME\n      value: \"root\"\n    - name: MONGODB_PASSWORD\n-->   value: \"xxxxxxxxxx\"","position":{"start":{"line":219,"column":1,"offset":10789},"end":{"line":222,"column":30,"offset":10908},"indent":[1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Once you have corrected the DNS names (or internal /etc/hosts file), install the Factory web app inside your cluster.","position":{"start":{"line":224,"column":1,"offset":10910},"end":{"line":224,"column":118,"offset":11027},"indent":[]}}],"position":{"start":{"line":224,"column":1,"offset":10910},"end":{"line":224,"column":118,"offset":11027},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"kubectl apply -f ./enterprise/yaml/factory/deployment.yaml","position":{"start":{"line":226,"column":1,"offset":11029},"end":{"line":226,"column":63,"offset":11091},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Test out configuration","position":{"start":{"line":228,"column":4,"offset":11096},"end":{"line":228,"column":26,"offset":11118},"indent":[]}}],"position":{"start":{"line":228,"column":1,"offset":11093},"end":{"line":228,"column":26,"offset":11118},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"If everything worked out as expected, you should now have following services in your cluster:","position":{"start":{"line":230,"column":1,"offset":11120},"end":{"line":230,"column":94,"offset":11213},"indent":[]}}],"position":{"start":{"line":230,"column":1,"offset":11120},"end":{"line":230,"column":94,"offset":11213},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"MongoDB","position":{"start":{"line":232,"column":5,"offset":11219},"end":{"line":232,"column":12,"offset":11226},"indent":[]}}],"position":{"start":{"line":232,"column":5,"offset":11219},"end":{"line":232,"column":12,"offset":11226},"indent":[]}}],"position":{"start":{"line":232,"column":1,"offset":11215},"end":{"line":232,"column":12,"offset":11226},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Traefik","position":{"start":{"line":233,"column":5,"offset":11231},"end":{"line":233,"column":12,"offset":11238},"indent":[]}}],"position":{"start":{"line":233,"column":5,"offset":11231},"end":{"line":233,"column":12,"offset":11238},"indent":[]}}],"position":{"start":{"line":233,"column":1,"offset":11227},"end":{"line":233,"column":12,"offset":11238},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Factory","position":{"start":{"line":234,"column":5,"offset":11243},"end":{"line":234,"column":12,"offset":11250},"indent":[]}}],"position":{"start":{"line":234,"column":5,"offset":11243},"end":{"line":234,"column":12,"offset":11250},"indent":[]}}],"position":{"start":{"line":234,"column":1,"offset":11239},"end":{"line":234,"column":12,"offset":11250},"indent":[]}}],"position":{"start":{"line":232,"column":1,"offset":11215},"end":{"line":234,"column":12,"offset":11250},"indent":[1,1]}},{"type":"paragraph","children":[{"type":"text","value":"It should look like this.","position":{"start":{"line":236,"column":1,"offset":11252},"end":{"line":236,"column":26,"offset":11277},"indent":[]}}],"position":{"start":{"line":236,"column":1,"offset":11252},"end":{"line":236,"column":26,"offset":11277},"indent":[]}},{"type":"code","lang":null,"meta":null,"value":"$ kubectl get pods\nNAME                              READY   STATUS    RESTARTS   AGE\nfactory-6f5c877d7c-hf77p          1/1     Running   0          2d11h\nmongodb-758d5c5ddd-qsfq9          1/1     Running   0          5m31s\ntraefik-7d566ccc47-mwslb          1/1     Running   0          4d12h","position":{"start":{"line":238,"column":1,"offset":11279},"end":{"line":242,"column":73,"offset":11591},"indent":[1,1,1,1]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Access the system","position":{"start":{"line":244,"column":4,"offset":11596},"end":{"line":244,"column":21,"offset":11613},"indent":[]}}],"position":{"start":{"line":244,"column":1,"offset":11593},"end":{"line":244,"column":21,"offset":11613},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Once everything is configured correctly your cluster and DNS, you should be able to setup the Factory application. By navigating to the Factory domain ","position":{"start":{"line":246,"column":1,"offset":11615},"end":{"line":246,"column":152,"offset":11766},"indent":[]}},{"type":"inlineCode","value":"factory.domain.com","position":{"start":{"line":246,"column":152,"offset":11766},"end":{"line":246,"column":172,"offset":11786},"indent":[]}},{"type":"text","value":" in your browser you will see the Factory login page showing up.","position":{"start":{"line":246,"column":172,"offset":11786},"end":{"line":246,"column":236,"offset":11850},"indent":[]}}],"position":{"start":{"line":246,"column":1,"offset":11615},"end":{"line":246,"column":236,"offset":11850},"indent":[]}},{"type":"paragraph","children":[{"type":"image","title":null,"url":"../../public/images/factory/kerberos-factory-loginpage.png","alt":"Factory","position":{"start":{"line":248,"column":1,"offset":11852},"end":{"line":248,"column":71,"offset":11922},"indent":[]}}],"position":{"start":{"line":248,"column":1,"offset":11852},"end":{"line":248,"column":71,"offset":11922},"indent":[]}},{"type":"export","value":"export const _frontmatter = {}","position":{"start":{"line":251,"column":1,"offset":11925},"end":{"line":251,"column":31,"offset":11955},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":251,"column":31,"offset":11955}}},"scopeImports":[],"scopeIdentifiers":[],"rawMDXOutput":"/* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsx mdx */\nimport DefaultLayout from \"/Users/i353408/Vagrant/www/repos/documentation/node_modules/gatsby-theme-docz/src/base/Layout.js\"\nimport ReplaceVersion from \"../components/ReplaceVersion\";\nexport const _frontmatter = {};\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\")\n  return <div {...props}/>\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = DefaultLayout\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n\n\n\n    <h1 {...{\n      \"id\": \"introduction\"\n    }}>{`Introduction`}</h1>\n    <p>{`Welcome to the Kerberos Enterprise Edge installation. This is the way to go if you want to install Kerberos Enterprise on your Baremetal infrastructure or inside your Private Cloud.`}</p>\n    <p><img alt=\"architecture kubernetes\" src={require(\"../../public/images/kerberos-agent-architecture-kubernetes.png\")} /></p>\n    <p>{`Before we can actual start installing the different deployments in our cluster, we need to make sure we have one available.`}</p>\n    <h1 {...{\n      \"id\": \"prerequisites\"\n    }}>{`Prerequisites`}</h1>\n    <h2 {...{\n      \"id\": \"docker\"\n    }}>{`Docker`}</h2>\n    <p>{`If you have a fresh Linux installation, make sure you have Docker installed. If not the case, this is how you can install it on a Ubuntu OSS.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`apt install docker.io -y`}</span></code></pre>\n    <h2 {...{\n      \"id\": \"kubernetes\"\n    }}>{`Kubernetes`}</h2>\n    <p>{`After Docker being installed go ahead and install the different Kubernetes servicess and tools.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`apt update -y`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`apt install apt-transport-https curl -y`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`apt-add-repository \"deb http://apt.kubernetes.io/ kubernetes-xenial main\"`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`apt update -y && apt install kubeadm kubelet kubectl kubernetes-cni -y`}</span></code></pre>\n    <p>{`Make sure you disable swap, this is required by Kubernetes.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`swapoff -a`}</span></code></pre>\n    <p>{`And if you want to make it permanent after every boot.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`sudo sed -i.bak '/ swap / s/^\\\\(.*\\\\)$/#\\\\1/g' /etc/fstab`}</span></code></pre>\n    <h1 {...{\n      \"id\": \"installation\"\n    }}>{`Installation`}</h1>\n    <p>{`Before initiating a new Kubernetes cluster, make sure you have properly cleaned up previous installation (if this was the case ofc).`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`kubeadm reset`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`rm -rf $HOME/.kube`}</span></code></pre>\n    <p>{`Initiate a new Kubernetes cluster using following command. This will use the current CIDR. If you want to use another CIDR, specify following arguments: `}<inlineCode parentName=\"p\">{`--pod-network-cidr=10.244.0.0/16`}</inlineCode>{`.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`kubeadm init`}</span></code></pre>\n    <p>{`Once successful you should see the following. Note the `}<inlineCode parentName=\"p\">{`discovery token`}</inlineCode>{` which you need to use to connect additional nodes to your cluster.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`Your Kubernetes control-plane has initialized successfully!`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}></span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`To start using your cluster, you need to run the following as a regular user:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}></span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`  mkdir -p $HOME/.kube`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`  sudo chown $(id -u):$(id -g) $HOME/.kube/config`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}></span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`You should now deploy a pod network to the cluster.`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`  https://kubernetes.io/docs/concepts/cluster-administration/addons/`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}></span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`Then you can join any number of worker nodes by running the following on each as root:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}></span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`kubeadm join 192.168.1.103:6443 --token ej7ckt.uof7o2iplqf0r2up \\\\`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`    --discovery-token-ca-cert-hash sha256:9cbcc00d34be2dbd605174802d9e52fbcdd617324c237bf58767b369fa586209`}</span></code></pre>\n    <p>{`Now we have a Kubernetes cluster, we need to make sure we add make it available in our `}<inlineCode parentName=\"p\">{`kubeconfig`}</inlineCode>{`. This will allow us to query our Kubernetes cluster with the `}<inlineCode parentName=\"p\">{`kubectl`}</inlineCode>{` command.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`mkdir -p $HOME/.kube`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`cp -i /etc/kubernetes/admin.conf $HOME/.kube/config`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`chown $(id -u):$(id -g) $HOME/.kube/config`}</span></code></pre>\n    <h2 {...{\n      \"id\": \"untaint-all-nodes\"\n    }}>{`Untaint all nodes`}</h2>\n    <p>{`By default, and in this example, we only have one node our master node. In a production scenario we would have additional worker nodes. By default the master nodes are marked as `}<inlineCode parentName=\"p\">{`tainted`}</inlineCode>{`, this means they cannot run workloads. To allow master nodes to run workloads, we need to untaint them. If we wouldn't do this our pods would never be scheduled, as we do not have worker nodes at this moment.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`kubectl taint nodes --all node-role.kubernetes.io/master-`}</span></code></pre>\n    <h2 {...{\n      \"id\": \"calico\"\n    }}>{`Calico`}</h2>\n    <p>{`Calico is an open source networking and network security solution for containers, virtual machines, and native host-based workloads. (`}<a parentName=\"p\" {...{\n        \"href\": \"https://www.projectcalico.org/\"\n      }}>{`https://www.projectcalico.org/`}</a>{`). We will use it as our network layer in our Kubernetes cluster. You could use otthers like Flannel aswell, but we prefer Calico.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`curl https://docs.projectcalico.org/manifests/calico.yaml -O`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`kubectl apply -f calico.yaml`}</span></code></pre>\n    <h2 {...{\n      \"id\": \"kerberos-enterprise\"\n    }}>{`Kerberos Enterprise`}</h2>\n    <p>{`Before setting up Kerberos Enterprise, some configuration needs to happen. First thing that we need to do is setting up the RBAC permissions (Role Based Access Control). We need to enable this to be able to query specific endpoints from the Kubernetes API. By default these endpoints are locked, so we need to unlock them.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`git clone https://github.com/kerberos-io/enterprise`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`kubectl create -f ./enterprise/yaml/factory/clusterrole.yaml`}</span></code></pre>\n    <p>{`This will make several actions, permissions, inside your cluster available. We need this to be able to create deployments from the Kerberos Enterprise web app.`}</p>\n    <h2 {...{\n      \"id\": \"metallb\"\n    }}>{`MetalLB`}</h2>\n    <p>{`In the Edge world, we do not have fancy Load balancers and Public IP from which we can benefit. To overcome this solutions such as MetalLB - Baremetal Load Balancer - have been developed (`}<a parentName=\"p\" {...{\n        \"href\": \"https://metallb.universe.tf/installation/\"\n      }}>{`https://metallb.universe.tf/installation/`}</a>{`). MetalLB will dedicate an internal IP address, or IP range, which will be assigned to one or more Load Balancers.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.5/manifests/namespace.yaml`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.5/manifests/metallb.yaml`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`kubectl create secret generic -n metallb-system memberlist --from-literal=secretkey=\"$(openssl rand -base64 128)\"`}</span></code></pre>\n    <p>{`After installing the different MetalLB components, we need to create a `}<inlineCode parentName=\"p\">{`configmap.yaml`}</inlineCode>{` file. This file contains information of how MetalLB can get and use internal IP's as LoadBalancers.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`  apiVersion: v1`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`  kind: ConfigMap`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`  metadata:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`    namespace: metallb-system`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`    name: config`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`  data:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`    config: |`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`      address-pools:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`      - name: default`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`        protocol: layer2`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`        addresses:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`-->     - 192.168.1.200-192.168.1.210`}</span></code></pre>\n    <p>{`You can change the IP range above to match your needs. MetalLB will use this range as a referance to assign IP addresses to your LoadBalancers. Once ready you can apply the configration map.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`kubectl apply -f ./enterprise/yaml/metallb/configmap.yaml`}</span></code></pre>\n    <h2 {...{\n      \"id\": \"helm\"\n    }}>{`Helm`}</h2>\n    <p>{`Before we can start with the real work, I know we had to do a lot of preparation, we have to install another helpful tool `}<inlineCode parentName=\"p\">{`Helm`}</inlineCode>{`. Helm is a package manager for Kubernetes, and really makes you life easier.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`chmod 700 get_helm.sh`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`./get_helm.sh`}</span></code></pre>\n    <p>{`This will make sure helm 3 is installed.`}</p>\n    <h2 {...{\n      \"id\": \"traefik\"\n    }}>{`Traefik`}</h2>\n    <p>{`To access the Kerberos Enterprise web application, we will create a service in the next paragraphs. This service will expose the web application as an Ingress. Thanks to our previous installation with MetalLB and Traefik (what we will do now), we will have a neat solution for managing our hostnames and Load Balancing IPs.`}</p>\n    <p>{`The idea is that Traefik, will have a dedicated IP address assigned from MetalLB, and will resolve the Ingress of our Kerberos Enterprise web app. Let's go ahead with installing Traefik.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`helm repo add stable https://charts.helm.sh/stable`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`helm install traefik -f ./enterprise/yaml/traefik/values.yaml stable/traefik`}</span></code></pre>\n    <h2 {...{\n      \"id\": \"mongodb\"\n    }}>{`MongoDB`}</h2>\n    <p>{`When using Kerberos Enterprise, it will generate configurations for every surveillance camera deployed. These configuration files are stored centrally in a MongoDB database. Therefore we use `}<inlineCode parentName=\"p\">{`helm`}</inlineCode>{` to install a MongoDB instance inside your cluster.`}</p>\n    <p>{`Before we can move into the installation of MongoDB, in contrary with the cloud installation, we will need to create a Persistent Volume (PV). For simplicity we will use `}<inlineCode parentName=\"p\">{`local-storage`}</inlineCode>{`, and make sure the volume is assigned to a specific node (hostname).`}</p>\n    <p>{`Create a folder on the node (VM), where you want to persist the data of MongoDB.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`mkdir /home/mongodb/`}</span></code></pre>\n    <p>{`Once done open the `}<inlineCode parentName=\"p\">{`./enterprise/yaml/mongodb/volume.yaml`}</inlineCode>{` file and make sure to change capacity, local path (if changed) and the hostname attribute (VM/machine, on which the directory is made available).`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`    spec:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`      capacity:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`-->    storage: 10Gi`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`      accessModes:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`      - ReadWriteOnce`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`      persistentVolumeReclaimPolicy: Recycle`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`      storageClassName: local-storage`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`      local:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`-->    path: /home/mongodb/`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`      nodeAffinity:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`        required:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`          nodeSelectorTerms:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`          - matchExpressions:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`            - key: kubernetes.io/hostname`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`              operator: In`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`              values:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`-->           - hostname`}</span></code></pre>\n    <p>{`After modified properly you can go ahead with creating the PV.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`kubectl create -f ./enterprise/yaml/mongodb/volume.yaml`}</span></code></pre>\n    <p>{`Have a look into the `}<inlineCode parentName=\"p\">{`yaml/mongodb/values.yaml`}</inlineCode>{` file, you will find plenty of configurations for your MongoDB instance. You will also find the attribute where you can change the root password of mongodb. If using Helm version 2, write `}<inlineCode parentName=\"p\">{`--name mongodb`}</inlineCode>{`.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`helm repo add bitnami https://charts.bitnami.com/bitnami`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`helm install mongodb bitnami/mongodb --values ./yaml/mongodb/values-edge.yaml`}</span></code></pre>\n    <p>{`Once installed succesfully the MongoDB instance, we should copy the password of the MongoDB instance. Once revealed copy the password, as we will need in the next steps.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`export MONGODB_ROOT_PASSWORD=$(kubectl get secret --namespace default mongodb -o jsonpath=\"{.data.mongodb-root-password}\" | base64 --decode)`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`echo $MONGODB_ROOT_PASSWORD`}</span></code></pre>\n    <h2 {...{\n      \"id\": \"kerberos-enterprise-web-app---the-factory\"\n    }}>{`Kerberos Enterprise Web App - The Factory`}</h2>\n    <p>{`The last step is to install the Kerberos Enterprise application. Kerberos Enterprise is managed through an application which we call the `}<inlineCode parentName=\"p\">{`Factory`}</inlineCode>{`. It is responsible for initiating the deployments inside your cluster. These deployments is what we also call (similar to the Open Source version) the machinery.`}</p>\n    <p>{`The Factory is shipped as a web app (React) which provides you with a tool to update your deployments (agents) easily, monitor them, etc. The Factory is the central portal for managing Kerberos Enterprise inside your cluster. However at any point you can fine-tune or take-over using the `}<inlineCode parentName=\"p\">{`kubectl`}</inlineCode>{` command.`}</p>\n    <p>{`Before installing the Factory web app, open the `}<inlineCode parentName=\"p\">{`./enterprise/yaml/factory/deployment.yaml`}</inlineCode>{` configuration file. At the bottom file you will find two endpoints, similar to the traefik config file. Update the domain names to your own domain, and add these to your DNS server (pointing to the same IP as the traefik EXTERNAL-IP).`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`    spec:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`      rules:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`-->   - host: factory.domain.com`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`        http:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`          paths:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`          - path: /`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`            backend:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`              serviceName: factory`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`              servicePort: 80`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`-->   - host: api.factory.domain.com`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`        http:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`          paths:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`          - path: /`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`            backend:`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`              serviceName: factory`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`              servicePort: 8081`}</span></code></pre>\n    <p>{`Modify the MongoDB credentials, and make sure they match the credentials of your MongoDB instance.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`    - name: MONGODB_USERNAME`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`      value: \"root\"`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`    - name: MONGODB_PASSWORD`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`-->   value: \"xxxxxxxxxx\"`}</span></code></pre>\n    <p>{`Once you have corrected the DNS names (or internal /etc/hosts file), install the Factory web app inside your cluster.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`kubectl apply -f ./enterprise/yaml/factory/deployment.yaml`}</span></code></pre>\n    <h2 {...{\n      \"id\": \"test-out-configuration\"\n    }}>{`Test out configuration`}</h2>\n    <p>{`If everything worked out as expected, you should now have following services in your cluster:`}</p>\n    <ul>\n      <li parentName=\"ul\">{`MongoDB`}</li>\n      <li parentName=\"ul\">{`Traefik`}</li>\n      <li parentName=\"ul\">{`Factory`}</li>\n    </ul>\n    <p>{`It should look like this.`}</p>\n    <pre {...{\n      \"className\": \"default-dark vscode-highlight\",\n      \"data-language\": \"\"\n    }}><code parentName=\"pre\" {...{\n        \"className\": \"vscode-highlight-code\"\n      }}><span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`$ kubectl get pods`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`NAME                              READY   STATUS    RESTARTS   AGE`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`factory-6f5c877d7c-hf77p          1/1     Running   0          2d11h`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`mongodb-758d5c5ddd-qsfq9          1/1     Running   0          5m31s`}</span>{`\n`}<span parentName=\"code\" {...{\n          \"className\": \"vscode-highlight-line\"\n        }}>{`traefik-7d566ccc47-mwslb          1/1     Running   0          4d12h`}</span></code></pre>\n    <h2 {...{\n      \"id\": \"access-the-system\"\n    }}>{`Access the system`}</h2>\n    <p>{`Once everything is configured correctly your cluster and DNS, you should be able to setup the Factory application. By navigating to the Factory domain `}<inlineCode parentName=\"p\">{`factory.domain.com`}</inlineCode>{` in your browser you will see the Factory login page showing up.`}</p>\n    <p><img alt=\"Factory\" src={require(\"../../public/images/factory/kerberos-factory-loginpage.png\")} /></p>\n\n    <style {...{\n      \"className\": \"vscode-highlight-styles\"\n    }}>{`\n  :root {\n  --vscode-highlight-padding-v: 1rem;\n  --vscode-highlight-padding-h: 1.5rem;\n  --vscode-highlight-padding-top: var(--vscode-highlight-padding-v);\n  --vscode-highlight-padding-right: var(--vscode-highlight-padding-h);\n  --vscode-highlight-padding-bottom: var(--vscode-highlight-padding-v);\n  --vscode-highlight-padding-left: var(--vscode-highlight-padding-h);\n  --vscode-highlight-border-radius: 8px;\n\n  --vscode-highlight-line-highlighted-background-color: transparent;\n  --vscode-highlight-line-highlighted-border-width: 4px;\n  --vscode-highlight-line-highlighted-border-color: transparent;\n}\n\n.vscode-highlight {\n  overflow: auto;\n  -webkit-overflow-scrolling: touch;\n  padding-top: 1rem;\n  padding-top: var(--vscode-highlight-padding-top);\n  padding-bottom: 1rem;\n  padding-bottom: var(--vscode-highlight-padding-bottom);\n  border-radius: 8px;\n  border-radius: var(--vscode-highlight-border-radius);\n  font-feature-settings: normal;\n}\n\n.vscode-highlight-code {\n  display: inline-block;\n  min-width: 100%;\n}\n\n.vscode-highlight-line {\n  display: inline-block;\n  box-sizing: border-box;\n  width: 100%;\n  padding-left: 1.5rem;\n  padding-left: var(--vscode-highlight-padding-left);\n  padding-right: 1.5rem;\n  padding-right: var(--vscode-highlight-padding-right);\n}\n\n.vscode-highlight-line-highlighted {\n  background-color: var(--vscode-highlight-line-highlighted-background-color);\n  box-shadow: inset var(--vscode-highlight-line-highlighted-border-width) 0 0 0 var(--vscode-highlight-line-highlighted-border-color);\n}\n\n  .default-dark {\nbackground-color: #1E1E1E;\ncolor: #D4D4D4;\n}\n`}</style>\n    </MDXLayout>;\n}\n\n;\nMDXContent.isMDXComponent = true;"}}